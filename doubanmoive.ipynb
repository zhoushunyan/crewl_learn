{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import chardet\n",
    "import re \n",
    "import xlwt\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHtml(index):\n",
    "    USER_AGENTS=[\"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; \\\n",
    "        .NET CLR 1.1.4322; .NET CLR 2.0.50727)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1;\\\n",
    "         .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.11 (KHTML, like Gecko)\\\n",
    "         Chrome/20.0.1132.11 TaoBrowser/2.0 Safari/536.11\",\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) \\\n",
    "        Chrome/21.0.1180.71 Safari/537.1 LBBROWSER\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732;\\\n",
    "         .NET4.0C; .NET4.0E; LBBROWSER)\",\n",
    "        \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; \\\n",
    "        SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; \\\n",
    "        Media Center PC 6.0; .NET4.0C; .NET4.0E)\"]\n",
    "    proxies=[{\"HTTP\":\"117.63.78.64:6666\"},\n",
    "               {\"HTTPS\":\"114.225.169.215:53128\"},\n",
    "               {\"HTTPS\":\"222.185.22.108:6666\"}]\n",
    "   # ,proxies=random.choice(proxies)\n",
    "    print(\"正在抓取第\",index+1,\"页面信息\")\n",
    "    url=\"https://movie.douban.com/top250?start='+str(index*25)+'&filter=\"\n",
    "    r=requests.get(url,headers={\"User-Agent\":random.choice(USER_AGENTS)})\n",
    "    code = chardet.detect(r.content)['encoding']\n",
    "    return r.content.decode(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg= re.compile('.*(\\d{4}).*')\n",
    "def getData(n):\n",
    "    datalist=[]\n",
    "    for step in range(n):\n",
    "        global reg\n",
    "        time.sleep(0.2)\n",
    "        html=getHtml(step)\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        parent = soup.find('div',attrs={'id':'content'}) #父节点\n",
    "        lis = parent.find_all('li')\n",
    "        \n",
    "        for li in lis:\n",
    "            data = []\n",
    "            film_name=li.find('div',attrs={'class':'hd'}).find('span').get_text()\n",
    "            data.append(film_name)\n",
    "            film_time_str=li.find('div',attrs={'class':'bd'}).find('p').get_text()\n",
    "            film_time=re.findall(reg,film_time_str)[0]\n",
    "            data.append(film_time)\n",
    "            film_score=li.find('div',attrs={'class':'star'}).find_all('span')[1].get_text()\n",
    "            data.append(film_score)\n",
    "            person_number=li.find('div',attrs={'class':'star'}).find_all('span')[3].get_text()\n",
    "            number= re.findall(re.compile('\\d*'),person_number)[0]\n",
    "            data.append(number)\n",
    "            #获取简评 ，因为个别没有标签，加以判断\n",
    "            if li.find('div',attrs={'class':'bd'}).find('p',attrs={'class':'quote'}):\n",
    "                evaluate = li.find('div',attrs={'class':'bd'}).find('p',attrs={'class':'quote'}).find('span').get_text()\n",
    "            else:\n",
    "                evaluate= ''\n",
    "            data.append(evaluate)\n",
    "            datalist.append(data)\n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SavetoExcel(n,fileName):\n",
    "    book=xlwt.Workbook()\n",
    "    sheet =book.add_sheet('豆瓣电影')\n",
    "    data=getData(n)\n",
    "    col=('电影名称','上映时间','电影评分','评分人数','电影简评')\n",
    "    for k,v in enumerate(col):\n",
    "        sheet.write(0,k,v)\n",
    "    for i,each in enumerate(data):\n",
    "        for j,value in enumerate(each):\n",
    "            sheet.write(i+1,j,value)\n",
    "    book.save(fileName)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在抓取第 1 页面信息\n",
      "正在抓取第 2 页面信息\n",
      "正在抓取第 3 页面信息\n",
      "正在抓取第 4 页面信息\n",
      "正在抓取第 5 页面信息\n",
      "正在抓取第 6 页面信息\n",
      "正在抓取第 7 页面信息\n",
      "正在抓取第 8 页面信息\n",
      "正在抓取第 9 页面信息\n",
      "正在抓取第 10 页面信息\n",
      "结束\n"
     ]
    }
   ],
   "source": [
    "SavetoExcel(10,'豆瓣.xls')\n",
    "print('结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
